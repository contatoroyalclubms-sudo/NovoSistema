# ğŸ§ª DOCUMENTAÃ‡ÃƒO DE TESTES

## VisÃ£o Geral do Framework de Testes

O sistema de eventos possui um framework abrangente de testes que garante qualidade, performance e confiabilidade em todos os nÃ­veis da aplicaÃ§Ã£o.

### ğŸ“Š EstatÃ­sticas de Cobertura

| Tipo de Teste   | Cobertura      | Quantidade   | Tempo MÃ©dio |
| --------------- | -------------- | ------------ | ----------- |
| **UnitÃ¡rios**   | 95%+           | 150+ testes  | 2-3 min     |
| **IntegraÃ§Ã£o**  | 85%+           | 50+ testes   | 5-8 min     |
| **E2E**         | 80%+           | 25+ cenÃ¡rios | 10-15 min   |
| **Performance** | 100% endpoints | 30+ mÃ©tricas | 3-5 min     |

---

## ğŸ¯ Tipos de Teste

### 1. **Testes UnitÃ¡rios** (`tests/unit/`)

Testam componentes isolados do sistema.

#### **Estrutura:**

```
tests/unit/
â”œâ”€â”€ test_auth.py           # Sistema de autenticaÃ§Ã£o
â”œâ”€â”€ test_events.py         # Gerenciamento de eventos
â”œâ”€â”€ test_users.py          # GestÃ£o de usuÃ¡rios
â”œâ”€â”€ test_inscricoes.py     # Sistema de inscriÃ§Ãµes
â”œâ”€â”€ test_checkins.py       # Check-ins e validaÃ§Ãµes
â”œâ”€â”€ test_gamificacao.py    # Sistema de gamificaÃ§Ã£o
â”œâ”€â”€ test_pdv.py           # Ponto de venda
â”œâ”€â”€ test_whatsapp.py      # IntegraÃ§Ã£o WhatsApp
â””â”€â”€ test_n8n.py           # IntegraÃ§Ã£o N8N
```

#### **Cobertura:**

- âœ… Todos os modelos de dados
- âœ… ServiÃ§os de negÃ³cio
- âœ… Validators e schemas
- âœ… UtilitÃ¡rios e helpers
- âœ… FunÃ§Ãµes de seguranÃ§a

#### **Exemplo de ExecuÃ§Ã£o:**

```bash
# Executar todos os testes unitÃ¡rios
python -m pytest tests/unit/ -v

# Com coverage
python -m pytest tests/unit/ --cov=app --cov-report=html

# Teste especÃ­fico
python -m pytest tests/unit/test_auth.py::TestAuthService::test_login_success -v
```

### 2. **Testes de IntegraÃ§Ã£o** (`tests/integration/`)

Testam interaÃ§Ã£o entre componentes e sistemas externos.

#### **Cobertura:**

- ğŸ”— APIs RESTful completas
- ğŸ”— IntegraÃ§Ã£o banco de dados
- ğŸ”— Sistema de cache (Redis)
- ğŸ”— WebSockets em tempo real
- ğŸ”— ServiÃ§os externos (WhatsApp, N8N)
- ğŸ”— Sistema de arquivos
- ğŸ”— AutenticaÃ§Ã£o e autorizaÃ§Ã£o

#### **CenÃ¡rios Testados:**

```python
# Fluxo completo de evento
1. Criar evento (Admin)
2. Listar eventos pÃºblicos
3. Inscrever usuÃ¡rio
4. Realizar check-in
5. Gerar estatÃ­sticas
6. Enviar notificaÃ§Ãµes

# Fluxo de gamificaÃ§Ã£o
1. AÃ§Ã£o do usuÃ¡rio
2. CÃ¡lculo de pontos
3. VerificaÃ§Ã£o de conquistas
4. AtualizaÃ§Ã£o de ranking
```

### 3. **Testes End-to-End** (`tests/e2e/`)

Simulam jornadas completas de usuÃ¡rio no navegador.

#### **Ferramentas:**

- **Selenium WebDriver** - AutomaÃ§Ã£o do navegador
- **Chrome Headless** - ExecuÃ§Ã£o sem interface
- **Screenshots** - Captura para debug
- **Responsividade** - Testes mobile/tablet

#### **Jornadas Testadas:**

##### **ğŸ‘¤ Jornada do Organizador:**

```
1. Login â†’ Dashboard
2. Criar Evento â†’ FormulÃ¡rio completo
3. Gerenciar InscriÃ§Ãµes
4. Configurar NotificaÃ§Ãµes
5. Visualizar RelatÃ³rios
6. Sistema PDV
```

##### **ğŸ‘¥ Jornada do Participante:**

```
1. Navegar Eventos (sem login)
2. Cadastro de UsuÃ¡rio
3. Login â†’ Perfil
4. InscriÃ§Ã£o em Evento
5. Download de Ingresso
6. Sistema de GamificaÃ§Ã£o
```

##### **ğŸ“± Responsividade:**

```
- Mobile (375px) - iPhone
- Tablet (768px) - iPad
- Desktop (1920px) - PC
```

### 4. **Testes de Performance** (`tests/performance/`)

Avaliam desempenho, escalabilidade e limites do sistema.

#### **MÃ©tricas Monitoradas:**

```python
THRESHOLDS = {
    "api_response_time": 1.0,        # segundos
    "database_query_time": 0.5,      # segundos
    "redis_operation_time": 0.1,     # segundos
    "memory_usage_mb": 512,          # MB
    "cpu_usage_percent": 80,         # %
    "concurrent_users": 100,         # usuÃ¡rios
    "requests_per_second": 1000,     # RPS
    "error_rate_threshold": 0.01     # 1%
}
```

#### **Tipos de Teste:**

- **Carga Crescente** - 1â†’100 usuÃ¡rios simultÃ¢neos
- **Stress Test** - Limites do sistema
- **Endurance** - Carga sustentada (30min+)
- **Spike** - Picos sÃºbitos de trÃ¡fego

---

## ğŸ› ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### **PrÃ©-requisitos**

```bash
# Instalar dependÃªncias
pip install -r requirements-test.txt

# DependÃªncias principais
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-cov>=4.0.0
pytest-html>=3.1.0
pytest-xdist>=3.0.0
selenium>=4.0.0
locust>=2.0.0
```

### **Estrutura de ConfiguraÃ§Ã£o**

#### **1. conftest.py** - ConfiguraÃ§Ã£o Global

```python
# Fixtures compartilhadas
# ConfiguraÃ§Ã£o de banco de dados
# Mocks de serviÃ§os externos
# UtilitÃ¡rios de teste
```

#### **2. pytest.ini** - ConfiguraÃ§Ã£o Pytest

```ini
[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
    "unit: Testes unitÃ¡rios",
    "integration: Testes de integraÃ§Ã£o",
    "e2e: Testes end-to-end",
    "performance: Testes de performance"
]
```

### **Scripts de ExecuÃ§Ã£o**

#### **ğŸš€ ExecuÃ§Ã£o Completa**

```bash
# Todos os testes
python run_tests.py --type all

# ExecuÃ§Ã£o rÃ¡pida (sem E2E/Performance)
python run_tests.py --quick

# Apenas unitÃ¡rios com coverage
python run_tests.py --type unit --verbose
```

#### **ğŸ¯ ExecuÃ§Ã£o EspecÃ­fica**

```bash
# Por tipo
python run_tests.py --type integration
python run_tests.py --type e2e --skip-e2e false
python run_tests.py --type performance

# Por marcador
pytest -m "unit and auth"
pytest -m "integration and not slow"
pytest -m "e2e and responsivo"
```

#### **ğŸ“Š Com RelatÃ³rios**

```bash
# Gerar relatÃ³rios HTML
python run_tests.py --type all --open-report

# Coverage detalhado
pytest --cov-report=html --cov-report=term-missing
```

---

## ğŸ“ Estrutura de Arquivos

```
tests/
â”œâ”€â”€ conftest.py                 # ConfiguraÃ§Ã£o global
â”œâ”€â”€ pytest.ini                 # ConfiguraÃ§Ã£o pytest
â”œâ”€â”€ fixtures/
â”‚   â””â”€â”€ test_data.py           # Dados de teste
â”œâ”€â”€ unit/                      # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”œâ”€â”€ test_events.py
â”‚   â”œâ”€â”€ test_users.py
â”‚   â”œâ”€â”€ test_inscricoes.py
â”‚   â”œâ”€â”€ test_checkins.py
â”‚   â”œâ”€â”€ test_gamificacao.py
â”‚   â”œâ”€â”€ test_pdv.py
â”‚   â”œâ”€â”€ test_whatsapp.py
â”‚   â””â”€â”€ test_n8n.py
â”œâ”€â”€ integration/               # Testes integraÃ§Ã£o
â”‚   â””â”€â”€ test_api_integration.py
â”œâ”€â”€ e2e/                       # Testes E2E
â”‚   â””â”€â”€ test_user_journeys.py
â””â”€â”€ performance/               # Testes performance
    â””â”€â”€ test_load_performance.py

# RelatÃ³rios (gerados)
test-results/
â”œâ”€â”€ consolidated-report.html    # RelatÃ³rio principal
â”œâ”€â”€ unit-tests-report.html     # UnitÃ¡rios
â”œâ”€â”€ integration-tests-report.html
â”œâ”€â”€ e2e-tests-report.html
â”œâ”€â”€ performance-tests-report.html
â”œâ”€â”€ coverage/                  # Coverage HTML
â””â”€â”€ screenshots/               # Screenshots E2E
```

---

## ğŸ”§ Fixtures e UtilitÃ¡rios

### **Fixtures Principais**

#### **Banco de Dados**

```python
@pytest.fixture
def db_session():
    # SessÃ£o isolada para cada teste

@pytest.fixture
def admin_user(db_session):
    # UsuÃ¡rio administrador

@pytest.fixture
def regular_user(db_session):
    # UsuÃ¡rio participante
```

#### **AutenticaÃ§Ã£o**

```python
@pytest.fixture
def admin_headers(admin_token):
    # Headers autenticados admin

@pytest.fixture
def user_headers(user_token):
    # Headers autenticados usuÃ¡rio
```

#### **Dados de Teste**

```python
@pytest.fixture
def valid_event_data():
    # Dados vÃ¡lidos para evento

@pytest.fixture
def sample_event(db_session, admin_user):
    # Evento criado no banco

@pytest.fixture
def multiple_events(db_session, admin_user):
    # Lote de eventos para testes
```

### **Mocks de ServiÃ§os**

#### **WhatsApp Service**

```python
@pytest.fixture
def mock_whatsapp_service():
    mock = Mock()
    mock.send_message = AsyncMock(return_value={
        "success": True,
        "message_id": "msg_123"
    })
    return mock
```

#### **Redis Cache**

```python
@pytest.fixture
def mock_redis_service():
    mock = Mock()
    mock.get = AsyncMock(return_value=None)
    mock.set = AsyncMock(return_value=True)
    return mock
```

---

## ğŸ“Š RelatÃ³rios e MÃ©tricas

### **Coverage Report**

- **HTML**: `htmlcov/index.html`
- **Terminal**: Resumo com linhas nÃ£o cobertas
- **XML**: Para integraÃ§Ã£o CI/CD

### **RelatÃ³rio Consolidado**

```json
{
  "timestamp": "2024-01-20T10:30:00",
  "total_duration": 125.45,
  "summary": {
    "unit_tests": true,
    "integration_tests": true,
    "e2e_tests": true,
    "performance_tests": true,
    "security_analysis": true
  }
}
```

### **MÃ©tricas de Performance**

```json
{
  "response_times": {
    "mean": 0.25,
    "p95": 0.45,
    "p99": 0.78
  },
  "throughput": {
    "rps": 850,
    "concurrent_users": 50
  },
  "resources": {
    "memory_peak_mb": 245,
    "cpu_avg_percent": 35
  }
}
```

---

## ğŸš¨ Troubleshooting

### **Problemas Comuns**

#### **1. Falha de DependÃªncias**

```bash
# Reinstalar dependÃªncias
pip install -r requirements-test.txt --force-reinstall
```

#### **2. Selenium WebDriver**

```bash
# Chrome nÃ£o encontrado
sudo apt-get install google-chrome-stable  # Linux
# ou baixar ChromeDriver manualmente
```

#### **3. Banco de Dados**

```bash
# Reset do banco de teste
rm test.db
python -c "from app.core.database import init_db; init_db()"
```

#### **4. Performance Tests Falhando**

```python
# Ajustar thresholds em conftest.py
PERFORMANCE_THRESHOLDS = {
    "api_response_time": 2.0,  # Aumentar limite
    # ...
}
```

### **Debug de Testes**

#### **Modo Verbose**

```bash
pytest -v -s tests/unit/test_auth.py
```

#### **Debug com PDB**

```python
def test_login():
    import pdb; pdb.set_trace()
    # Debug interativo
```

#### **Screenshots E2E**

```python
# AutomÃ¡tico em falhas
utils.take_screenshot(driver, "failure_login")
```

---

## ğŸ“ˆ CI/CD Integration

### **GitHub Actions**

```yaml
# .github/workflows/tests.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: pip install -r requirements-test.txt
      - name: Run tests
        run: python run_tests.py --type all --quick
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

### **MÃ©tricas de Qualidade**

- **Coverage mÃ­nimo**: 80%
- **Performance**: < 1s response time
- **Security**: Zero vulnerabilidades crÃ­ticas
- **Code Quality**: Flake8 + Black compliance

---

## ğŸ¯ Roadmap de Testes

### **Fase Atual** âœ…

- [x] Framework completo implementado
- [x] Testes unitÃ¡rios (95% coverage)
- [x] Testes de integraÃ§Ã£o
- [x] Testes E2E bÃ¡sicos
- [x] Testes de performance
- [x] RelatÃ³rios automatizados

### **PrÃ³ximas Melhorias** ğŸš€

- [ ] Testes de acessibilidade (WCAG)
- [ ] Testes de seguranÃ§a avanÃ§ados
- [ ] Testes de compatibilidade (browsers)
- [ ] Testes de carga distribuÃ­da
- [ ] Monitoramento contÃ­nuo
- [ ] Visual regression testing

---

## ğŸ“ Suporte

Para dÃºvidas sobre o framework de testes:

1. **DocumentaÃ§Ã£o**: Este arquivo
2. **Exemplos**: Consultar testes existentes
3. **Debug**: Usar modo verbose (`-v -s`)
4. **Issues**: Criar issue no repositÃ³rio

**Contato**: Equipe de Desenvolvimento
