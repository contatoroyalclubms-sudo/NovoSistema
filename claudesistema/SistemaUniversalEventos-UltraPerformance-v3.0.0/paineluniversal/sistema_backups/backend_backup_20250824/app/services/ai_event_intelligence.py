"""
AI-Powered Event Intelligence System
Sistema Universal de GestÃ£o de Eventos - ULTRA-EXPERT

MÃ³dulo avanÃ§ado de inteligÃªncia artificial para:
- GeraÃ§Ã£o inteligente de conteÃºdo de eventos
- Sistema de recomendaÃ§Ãµes baseado em ML
- OtimizaÃ§Ã£o automÃ¡tica de eventos
- Analytics preditivos para participaÃ§Ã£o
- PersonalizaÃ§Ã£o avanÃ§ada de experiÃªncias
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
import openai
from openai import AsyncOpenAI
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
import pandas as pd
import redis.asyncio as aioredis

from ..core.config import settings

logger = logging.getLogger(__name__)

@dataclass
class EventInsight:
    """Estrutura para insights de eventos"""
    event_id: str
    insight_type: str
    confidence_score: float
    recommendations: List[str]
    predicted_metrics: Dict[str, float]
    generated_content: Optional[Dict[str, str]] = None
    timestamp: str = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow().isoformat()

@dataclass
class PersonalizationProfile:
    """Perfil de personalizaÃ§Ã£o do usuÃ¡rio"""
    user_id: str
    preferences: Dict[str, float]
    event_history: List[str]
    engagement_score: float
    predicted_interests: List[str]
    last_updated: str

class AIEventIntelligenceEngine:
    """
    Motor de InteligÃªncia Artificial para Eventos
    
    Funcionalidades:
    1. GeraÃ§Ã£o inteligente de conteÃºdo
    2. Sistema de recomendaÃ§Ãµes ML
    3. OtimizaÃ§Ã£o automÃ¡tica de eventos
    4. Analytics preditivos
    5. PersonalizaÃ§Ã£o avanÃ§ada
    """
    
    def __init__(self):
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.redis_client = None
        self.tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.recommendation_model = None
        self.user_profiles: Dict[str, PersonalizationProfile] = {}
        self.event_embeddings: Dict[str, np.ndarray] = {}
        
    async def initialize(self):
        """Inicializar o sistema de IA"""
        try:
            # Conectar ao Redis para cache
            self.redis_client = aioredis.from_url(
                settings.REDIS_URL or "redis://localhost:6379"
            )
            
            # Carregar modelos prÃ©-treinados se existirem
            await self._load_existing_models()
            
            logger.info("âœ… AI Event Intelligence Engine initialized")
            
        except Exception as e:
            logger.error(f"âŒ Error initializing AI Engine: {e}")
            raise
    
    async def _load_existing_models(self):
        """Carregar modelos existentes do cache"""
        try:
            if self.redis_client:
                # Carregar perfis de usuÃ¡rio
                user_profiles_data = await self.redis_client.get("ai:user_profiles")
                if user_profiles_data:
                    profiles_dict = json.loads(user_profiles_data)
                    for user_id, profile_data in profiles_dict.items():
                        self.user_profiles[user_id] = PersonalizationProfile(**profile_data)
                
                # Carregar embeddings de eventos
                embeddings_data = await self.redis_client.get("ai:event_embeddings")
                if embeddings_data:
                    embeddings_dict = json.loads(embeddings_data)
                    for event_id, embedding_list in embeddings_dict.items():
                        self.event_embeddings[event_id] = np.array(embedding_list)
                        
        except Exception as e:
            logger.warning(f"âš ï¸ Could not load existing models: {e}")

    async def generate_intelligent_event_content(
        self, 
        event_data: Dict[str, Any],
        content_types: List[str] = None
    ) -> Dict[str, str]:
        """
        Gerar conteÃºdo inteligente para eventos usando GPT-4
        
        Args:
            event_data: Dados do evento
            content_types: Tipos de conteÃºdo a gerar
            
        Returns:
            Dict com conteÃºdo gerado por tipo
        """
        if content_types is None:
            content_types = ["description", "marketing_copy", "social_media", "email_subject", "hashtags"]
        
        generated_content = {}
        
        try:
            # AnÃ¡lise contextual do evento
            event_context = await self._analyze_event_context(event_data)
            
            for content_type in content_types:
                prompt = self._build_content_generation_prompt(
                    event_data, content_type, event_context
                )
                
                response = await self.openai_client.chat.completions.create(
                    model=settings.OPENAI_MODEL,
                    messages=[
                        {
                            "role": "system", 
                            "content": "VocÃª Ã© um especialista em marketing de eventos e copywriting, criando conteÃºdo altamente envolvente e convertÃ­vel."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=settings.OPENAI_MAX_TOKENS,
                    temperature=settings.OPENAI_TEMPERATURE,
                    frequency_penalty=0.1,
                    presence_penalty=0.1
                )
                
                generated_content[content_type] = response.choices[0].message.content.strip()
                
                # Pequeno delay para respeitar rate limits
                await asyncio.sleep(0.1)
            
            # Cache do conteÃºdo gerado
            if self.redis_client:
                cache_key = f"ai:generated_content:{event_data.get('id', 'unknown')}"
                await self.redis_client.setex(
                    cache_key, 
                    3600 * 24,  # 24 horas
                    json.dumps(generated_content)
                )
            
            logger.info(f"âœ¨ Generated intelligent content for event {event_data.get('name', 'Unknown')}")
            return generated_content
            
        except Exception as e:
            logger.error(f"âŒ Error generating intelligent content: {e}")
            return self._fallback_content(event_data, content_types)

    def _build_content_generation_prompt(
        self, 
        event_data: Dict[str, Any], 
        content_type: str, 
        context: Dict[str, Any]
    ) -> str:
        """Construir prompt especÃ­fico para tipo de conteÃºdo"""
        
        base_info = f"""
        INFORMAÃ‡Ã•ES DO EVENTO:
        Nome: {event_data.get('name', 'N/A')}
        Tipo: {event_data.get('type', 'N/A')}
        Data: {event_data.get('date', 'N/A')}
        Local: {event_data.get('location', 'N/A')}
        PÃºblico-alvo: {event_data.get('target_audience', 'Geral')}
        Capacidade: {event_data.get('capacity', 'N/A')}
        PreÃ§o: {event_data.get('price', 'Gratuito')}
        
        CONTEXTO INTELIGENTE:
        Categoria de pÃºblico: {context.get('audience_category', 'Misto')}
        NÃ­vel de interesse estimado: {context.get('interest_level', 'Alto')}
        TendÃªncias relevantes: {', '.join(context.get('trending_topics', []))}
        """
        
        prompts = {
            "description": f"""
            {base_info}
            
            Crie uma descriÃ§Ã£o ULTRA-ENVOLVENTE e profissional que:
            âœ¨ Capture a essÃªncia Ãºnica do evento
            ğŸ¯ Fale diretamente com o pÃºblico-alvo
            ğŸ”¥ Use gatilhos mentais de urgÃªncia e exclusividade
            ğŸ’ Destaque benefÃ­cios transformadores
            ğŸ“ˆ Inclua elementos de prova social
            
            Estrutura: 3-4 parÃ¡grafos, linguagem persuasiva mas profissional.
            """,
            
            "marketing_copy": f"""
            {base_info}
            
            Crie um copy de marketing IRRESISTÃVEL que:
            ğŸš€ Comece com um hook poderoso
            ğŸ’« Use tÃ©cnicas de storytelling
            âš¡ Inclua call-to-action magnÃ©tico
            ğŸ Crie senso de urgÃªncia/escassez
            ğŸ† Destaque transformaÃ§Ã£o/resultado
            
            Formato: Ideal para landing page, mÃ¡ximo 200 palavras.
            """,
            
            "social_media": f"""
            {base_info}
            
            Crie posts para redes sociais que VIRALIZAM:
            ğŸ“± 3 versÃµes: Instagram, LinkedIn, Twitter
            ğŸ”¥ Use emojis estratÃ©gicos
            #ï¸âƒ£ Inclua hashtags relevantes
            ğŸ“¸ Sugira elementos visuais
            ğŸ’¬ Inclua pergunta para engajamento
            
            Cada post deve ser otimizado para sua plataforma.
            """,
            
            "email_subject": f"""
            {base_info}
            
            Crie 5 assuntos de email IRRESISTÃVEIS que garantam alta taxa de abertura:
            ğŸ“§ Use curiosidade e urgÃªncia
            ğŸ¯ Personalize para o pÃºblico
            âš¡ MÃ¡ximo 50 caracteres
            ğŸ”¥ Evite spam words
            âœ¨ Seja especÃ­fico e benefÃ­cio-focado
            
            Ordene por potencial de conversÃ£o.
            """,
            
            "hashtags": f"""
            {base_info}
            
            Crie estratÃ©gia completa de hashtags:
            ğŸ·ï¸ 10 hashtags de nicho especÃ­fico
            ğŸ“ˆ 5 hashtags populares (alta busca)
            ğŸ¯ 3 hashtags de marca/evento
            ğŸŒŸ 2 hashtags trending atuais
            
            Inclua volume estimado de busca e estratÃ©gia de uso.
            """
        }
        
        return prompts.get(content_type, prompts["description"])

    async def _analyze_event_context(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analisar contexto inteligente do evento"""
        
        # AnÃ¡lise bÃ¡sica do tipo de evento
        event_type = event_data.get('type', '').lower()
        
        # CategorizaÃ§Ã£o de pÃºblico
        audience_categories = {
            'workshop': 'Profissionais em busca de conhecimento',
            'conference': 'Executivos e especialistas',
            'networking': 'Empreendedores e profissionais',
            'concert': 'Jovens e entusiastas musicais',
            'seminar': 'Estudantes e profissionais',
            'party': 'Jovens adultos sociais'
        }
        
        audience_category = audience_categories.get(event_type, 'PÃºblico geral')
        
        # TÃ³picos trending simulados (em produÃ§Ã£o, integraria com APIs de trend)
        trending_topics = [
            "InteligÃªncia Artificial",
            "Sustentabilidade",
            "Networking Digital",
            "InovaÃ§Ã£o",
            "TransformaÃ§Ã£o Digital"
        ]
        
        return {
            'audience_category': audience_category,
            'interest_level': 'Alto',
            'trending_topics': trending_topics[:3]
        }

    async def build_recommendation_system(
        self, 
        events_data: List[Dict[str, Any]], 
        user_interactions: List[Dict[str, Any]]
    ) -> None:
        """
        Construir sistema de recomendaÃ§Ãµes baseado em Machine Learning
        
        Args:
            events_data: Lista de dados de eventos
            user_interactions: Lista de interaÃ§Ãµes dos usuÃ¡rios
        """
        try:
            # Criar embeddings dos eventos
            event_texts = []
            event_ids = []
            
            for event in events_data:
                # Combinar features textuais do evento
                text_features = [
                    event.get('name', ''),
                    event.get('description', ''),
                    event.get('type', ''),
                    event.get('category', ''),
                    ' '.join(event.get('tags', []))
                ]
                combined_text = ' '.join(filter(None, text_features))
                event_texts.append(combined_text)
                event_ids.append(event.get('id'))
            
            # Criar matriz TF-IDF
            if event_texts:
                tfidf_matrix = self.tfidf_vectorizer.fit_transform(event_texts)
                
                # Armazenar embeddings
                for i, event_id in enumerate(event_ids):
                    self.event_embeddings[event_id] = tfidf_matrix[i].toarray().flatten()
            
            # Construir perfis de usuÃ¡rios
            await self._build_user_profiles(user_interactions, events_data)
            
            # Treinar modelo de clustering para segmentaÃ§Ã£o
            if len(events_data) > 5:
                embeddings_matrix = np.array(list(self.event_embeddings.values()))
                n_clusters = min(5, len(events_data) // 2)
                self.recommendation_model = KMeans(n_clusters=n_clusters, random_state=42)
                self.recommendation_model.fit(embeddings_matrix)
            
            # Cache dos modelos
            await self._cache_models()
            
            logger.info(f"ğŸ¤– Recommendation system built with {len(events_data)} events")
            
        except Exception as e:
            logger.error(f"âŒ Error building recommendation system: {e}")

    async def _build_user_profiles(
        self, 
        user_interactions: List[Dict[str, Any]], 
        events_data: List[Dict[str, Any]]
    ) -> None:
        """Construir perfis inteligentes de usuÃ¡rios"""
        
        events_dict = {event['id']: event for event in events_data}
        user_data = {}
        
        # Agregar interaÃ§Ãµes por usuÃ¡rio
        for interaction in user_interactions:
            user_id = interaction.get('user_id')
            if not user_id:
                continue
                
            if user_id not in user_data:
                user_data[user_id] = {
                    'events_attended': [],
                    'event_types': [],
                    'ratings': [],
                    'total_interactions': 0
                }
            
            event_id = interaction.get('event_id')
            if event_id in events_dict:
                event = events_dict[event_id]
                user_data[user_id]['events_attended'].append(event_id)
                user_data[user_id]['event_types'].append(event.get('type', ''))
                user_data[user_id]['ratings'].append(interaction.get('rating', 5))
                user_data[user_id]['total_interactions'] += 1
        
        # Criar perfis de personalizaÃ§Ã£o
        for user_id, data in user_data.items():
            # Calcular preferÃªncias por tipo de evento
            type_counts = {}
            for event_type in data['event_types']:
                type_counts[event_type] = type_counts.get(event_type, 0) + 1
            
            total_types = len(data['event_types'])
            preferences = {
                event_type: count / total_types 
                for event_type, count in type_counts.items()
            } if total_types > 0 else {}
            
            # Calcular score de engajamento
            avg_rating = np.mean(data['ratings']) if data['ratings'] else 3.0
            interaction_factor = min(data['total_interactions'] / 10, 1.0)
            engagement_score = (avg_rating / 5.0) * interaction_factor
            
            # Predizer interesses futuros
            predicted_interests = list(type_counts.keys())[:3]
            
            # Criar perfil
            profile = PersonalizationProfile(
                user_id=user_id,
                preferences=preferences,
                event_history=data['events_attended'],
                engagement_score=engagement_score,
                predicted_interests=predicted_interests,
                last_updated=datetime.utcnow().isoformat()
            )
            
            self.user_profiles[user_id] = profile

    async def get_personalized_recommendations(
        self, 
        user_id: str, 
        available_events: List[Dict[str, Any]],
        limit: int = 10
    ) -> List[Tuple[str, float]]:
        """
        Obter recomendaÃ§Ãµes personalizadas para usuÃ¡rio
        
        Args:
            user_id: ID do usuÃ¡rio
            available_events: Eventos disponÃ­veis
            limit: Limite de recomendaÃ§Ãµes
            
        Returns:
            Lista de (event_id, score) ordenada por relevÃ¢ncia
        """
        try:
            user_profile = self.user_profiles.get(user_id)
            if not user_profile:
                # Retornar recomendaÃ§Ãµes populares para usuÃ¡rios novos
                return await self._get_popular_events(available_events, limit)
            
            recommendations = []
            
            for event in available_events:
                event_id = event.get('id')
                
                # Skip eventos jÃ¡ participados
                if event_id in user_profile.event_history:
                    continue
                
                score = await self._calculate_recommendation_score(user_profile, event)
                recommendations.append((event_id, score))
            
            # Ordenar por score e retornar top eventos
            recommendations.sort(key=lambda x: x[1], reverse=True)
            return recommendations[:limit]
            
        except Exception as e:
            logger.error(f"âŒ Error getting personalized recommendations: {e}")
            return []

    async def _calculate_recommendation_score(
        self, 
        user_profile: PersonalizationProfile, 
        event: Dict[str, Any]
    ) -> float:
        """Calcular score de recomendaÃ§Ã£o usando mÃºltiplos fatores"""
        
        score = 0.0
        
        # Fator 1: PreferÃªncia por tipo de evento (40% do peso)
        event_type = event.get('type', '').lower()
        type_preference = user_profile.preferences.get(event_type, 0)
        score += type_preference * 0.4
        
        # Fator 2: Similaridade semÃ¢ntica com eventos passados (30% do peso)
        event_id = event.get('id')
        if event_id in self.event_embeddings:
            semantic_score = await self._calculate_semantic_similarity(
                user_profile, event_id
            )
            score += semantic_score * 0.3
        
        # Fator 3: Engajamento histÃ³rico do usuÃ¡rio (20% do peso)
        score += user_profile.engagement_score * 0.2
        
        # Fator 4: Popularidade e tendÃªncias do evento (10% do peso)
        popularity_score = await self._calculate_popularity_score(event)
        score += popularity_score * 0.1
        
        return min(score, 1.0)  # Normalizar entre 0 e 1

    async def _calculate_semantic_similarity(
        self, 
        user_profile: PersonalizationProfile, 
        event_id: str
    ) -> float:
        """Calcular similaridade semÃ¢ntica com eventos do histÃ³rico"""
        
        if not user_profile.event_history or event_id not in self.event_embeddings:
            return 0.0
        
        target_embedding = self.event_embeddings[event_id]
        similarities = []
        
        for past_event_id in user_profile.event_history[-5:]:  # Ãšltimos 5 eventos
            if past_event_id in self.event_embeddings:
                past_embedding = self.event_embeddings[past_event_id]
                similarity = cosine_similarity([target_embedding], [past_embedding])[0][0]
                similarities.append(similarity)
        
        return np.mean(similarities) if similarities else 0.0

    async def _calculate_popularity_score(self, event: Dict[str, Any]) -> float:
        """Calcular score de popularidade do evento"""
        
        # Fatores de popularidade simulados (em produÃ§Ã£o, usar dados reais)
        capacity = event.get('capacity', 100)
        registered = event.get('registered_count', 0)
        
        # Taxa de ocupaÃ§Ã£o
        occupancy_rate = registered / max(capacity, 1)
        
        # Score baseado na ocupaÃ§Ã£o (eventos com 50-80% sÃ£o mais atraentes)
        if 0.5 <= occupancy_rate <= 0.8:
            return 1.0
        elif occupancy_rate < 0.5:
            return occupancy_rate * 2  # Linear atÃ© 50%
        else:
            return max(0.2, 2 - occupancy_rate)  # Decrescente apÃ³s 80%

    async def _get_popular_events(
        self, 
        events: List[Dict[str, Any]], 
        limit: int
    ) -> List[Tuple[str, float]]:
        """Obter eventos populares para usuÃ¡rios novos"""
        
        popular_events = []
        
        for event in events:
            popularity_score = await self._calculate_popularity_score(event)
            popular_events.append((event.get('id'), popularity_score))
        
        popular_events.sort(key=lambda x: x[1], reverse=True)
        return popular_events[:limit]

    async def predict_event_success(
        self, 
        event_data: Dict[str, Any],
        historical_data: List[Dict[str, Any]] = None
    ) -> EventInsight:
        """
        Predizer sucesso de evento usando analytics preditivos
        
        Args:
            event_data: Dados do evento
            historical_data: Dados histÃ³ricos similares
            
        Returns:
            Insights e prediÃ§Ãµes
        """
        try:
            event_id = event_data.get('id', 'unknown')
            
            # AnÃ¡lise preditiva usando GPT-4
            prediction_prompt = self._build_prediction_prompt(event_data, historical_data)
            
            response = await self.openai_client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "VocÃª Ã© um especialista em analytics de eventos com capacidade de prediÃ§Ã£o precisa baseada em dados."
                    },
                    {"role": "user", "content": prediction_prompt}
                ],
                max_tokens=800,
                temperature=0.3  # Baixa temperatura para prediÃ§Ãµes mais precisas
            )
            
            prediction_text = response.choices[0].message.content
            
            # Extrair mÃ©tricas preditas (simplificado)
            predicted_metrics = {
                "attendance_rate": 0.75,  # Em produÃ§Ã£o, extrair do texto da IA
                "satisfaction_score": 4.2,
                "engagement_level": 0.85,
                "revenue_projection": event_data.get('capacity', 100) * event_data.get('price', 0) * 0.75,
                "social_media_reach": event_data.get('capacity', 100) * 3
            }
            
            # Gerar recomendaÃ§Ãµes especÃ­ficas
            recommendations = await self._extract_recommendations_from_prediction(prediction_text)
            
            insight = EventInsight(
                event_id=event_id,
                insight_type="success_prediction",
                confidence_score=0.85,
                recommendations=recommendations,
                predicted_metrics=predicted_metrics
            )
            
            # Cache do insight
            if self.redis_client:
                cache_key = f"ai:insight:{event_id}"
                await self.redis_client.setex(
                    cache_key,
                    3600 * 6,  # 6 horas
                    json.dumps(asdict(insight))
                )
            
            logger.info(f"ğŸ”® Generated success prediction for event {event_id}")
            return insight
            
        except Exception as e:
            logger.error(f"âŒ Error predicting event success: {e}")
            return EventInsight(
                event_id=event_data.get('id', 'unknown'),
                insight_type="error",
                confidence_score=0.0,
                recommendations=["Erro na anÃ¡lise preditiva"],
                predicted_metrics={}
            )

    def _build_prediction_prompt(
        self, 
        event_data: Dict[str, Any], 
        historical_data: List[Dict[str, Any]] = None
    ) -> str:
        """Construir prompt para prediÃ§Ã£o de sucesso"""
        
        prompt = f"""
        ANÃLISE PREDITIVA DE EVENTO
        
        DADOS DO EVENTO:
        Nome: {event_data.get('name')}
        Tipo: {event_data.get('type')}
        Data: {event_data.get('date')}
        HorÃ¡rio: {event_data.get('time')}
        Local: {event_data.get('location')}
        Capacidade: {event_data.get('capacity')}
        PreÃ§o: R$ {event_data.get('price', 0)}
        PÃºblico-alvo: {event_data.get('target_audience')}
        Categoria: {event_data.get('category')}
        
        ANÃLISE SOLICITADA:
        Com base nos dados fornecidos, forneÃ§a uma anÃ¡lise preditiva DETALHADA incluindo:
        
        1. PREDIÃ‡ÃƒO DE PARTICIPAÃ‡ÃƒO:
        - Taxa de ocupaÃ§Ã£o esperada (%)
        - NÃºmero estimado de participantes
        - Fatores que influenciam a participaÃ§Ã£o
        
        2. PREDIÃ‡ÃƒO DE SATISFAÃ‡ÃƒO:
        - Score de satisfaÃ§Ã£o esperado (1-5)
        - Aspectos que podem gerar satisfaÃ§Ã£o
        - PossÃ­veis pontos de fricÃ§Ã£o
        
        3. PREDIÃ‡ÃƒO DE ENGAJAMENTO:
        - NÃ­vel de interaÃ§Ã£o esperado
        - Potencial viral nas redes sociais
        - Probabilidade de recomendaÃ§Ã£o
        
        4. PREDIÃ‡ÃƒO FINANCEIRA:
        - Receita estimada
        - ROI projetado
        - Custos crÃ­ticos a considerar
        
        5. RECOMENDAÃ‡Ã•ES ESTRATÃ‰GICAS:
        - 5 aÃ§Ãµes especÃ­ficas para maximizar sucesso
        - Alertas e riscos a monitorar
        - OtimizaÃ§Ãµes recomendadas
        
        Seja especÃ­fico, use nÃºmeros quando possÃ­vel e justifique suas prediÃ§Ãµes.
        """
        
        if historical_data:
            prompt += f"\n\nDADOS HISTÃ“RICOS SIMILARES:\n"
            for i, hist_event in enumerate(historical_data[:3], 1):
                prompt += f"{i}. {hist_event.get('name')} - ParticipaÃ§Ã£o: {hist_event.get('attendance_rate', 'N/A')}%, SatisfaÃ§Ã£o: {hist_event.get('satisfaction', 'N/A')}\n"
        
        return prompt

    async def _extract_recommendations_from_prediction(self, prediction_text: str) -> List[str]:
        """Extrair recomendaÃ§Ãµes do texto de prediÃ§Ã£o"""
        
        recommendations = []
        lines = prediction_text.split('\n')
        
        in_recommendations = False
        for line in lines:
            line = line.strip()
            if 'recomendaÃ§Ãµes' in line.lower() or 'aÃ§Ãµes' in line.lower():
                in_recommendations = True
                continue
            
            if in_recommendations and line:
                # Extrair recomendaÃ§Ãµes numeradas ou com bullets
                if any(line.startswith(marker) for marker in ['1.', '2.', '3.', '4.', '5.', '-', 'â€¢']):
                    # Limpar marcadores
                    clean_rec = line
                    for marker in ['1.', '2.', '3.', '4.', '5.', '-', 'â€¢']:
                        clean_rec = clean_rec.replace(marker, '').strip()
                    
                    if clean_rec:
                        recommendations.append(clean_rec)
                
                # Parar se encontrar nova seÃ§Ã£o
                if line.isupper() or line.startswith('6.'):
                    break
        
        return recommendations[:5]  # MÃ¡ximo 5 recomendaÃ§Ãµes

    async def optimize_event_automatically(
        self, 
        event_id: str, 
        current_metrics: Dict[str, float]
    ) -> Dict[str, Any]:
        """
        Otimizar evento automaticamente baseado em mÃ©tricas atuais
        
        Args:
            event_id: ID do evento
            current_metrics: MÃ©tricas atuais do evento
            
        Returns:
            OtimizaÃ§Ãµes sugeridas e implementÃ¡veis
        """
        try:
            # AnÃ¡lise de performance atual
            performance_analysis = await self._analyze_current_performance(current_metrics)
            
            # Gerar otimizaÃ§Ãµes usando IA
            optimization_prompt = f"""
            OTIMIZAÃ‡ÃƒO AUTOMÃTICA DE EVENTO
            
            ID do Evento: {event_id}
            
            MÃ‰TRICAS ATUAIS:
            {json.dumps(current_metrics, indent=2)}
            
            ANÃLISE DE PERFORMANCE:
            {json.dumps(performance_analysis, indent=2)}
            
            ForneÃ§a otimizaÃ§Ãµes AUTOMATIZÃVEIS especÃ­ficas:
            
            1. OTIMIZAÃ‡Ã•ES DE PREÃ‡O:
            - Ajustes de precificaÃ§Ã£o dinÃ¢mica
            - EstratÃ©gias de desconto
            - Bundling de produtos
            
            2. OTIMIZAÃ‡Ã•ES DE MARKETING:
            - Ajustes em campanhas
            - SegmentaÃ§Ã£o de pÃºblico
            - Canais de divulgaÃ§Ã£o
            
            3. OTIMIZAÃ‡Ã•ES DE EXPERIÃŠNCIA:
            - Melhorias na agenda
            - Recursos adicionais
            - PersonalizaÃ§Ã£o
            
            4. OTIMIZAÃ‡Ã•ES OPERACIONAIS:
            - Ajustes de capacidade
            - LogÃ­stica melhorada
            - Tecnologia adicional
            
            Para cada otimizaÃ§Ã£o, inclua:
            - Impacto esperado (alto/mÃ©dio/baixo)
            - Facilidade de implementaÃ§Ã£o (1-10)
            - Tempo de implementaÃ§Ã£o
            - MÃ©trica alvo a melhorar
            
            Formato: JSON estruturado para fÃ¡cil parsing.
            """
            
            response = await self.openai_client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "VocÃª Ã© um especialista em otimizaÃ§Ã£o de eventos com foco em implementaÃ§Ãµes automatizÃ¡veis e mensurÃ¡veis."
                    },
                    {"role": "user", "content": optimization_prompt}
                ],
                max_tokens=1000,
                temperature=0.4
            )
            
            optimization_text = response.choices[0].message.content
            
            # Processar otimizaÃ§Ãµes (simplificado para demonstraÃ§Ã£o)
            optimizations = {
                "pricing_optimizations": [
                    {
                        "action": "dynamic_pricing",
                        "description": "Implementar preÃ§os dinÃ¢micos baseados na demanda",
                        "impact": "alto",
                        "implementation_ease": 8,
                        "target_metric": "revenue"
                    }
                ],
                "marketing_optimizations": [
                    {
                        "action": "audience_segmentation",
                        "description": "Segmentar campanhas por perfil de participante",
                        "impact": "mÃ©dio",
                        "implementation_ease": 6,
                        "target_metric": "attendance_rate"
                    }
                ],
                "experience_optimizations": [
                    {
                        "action": "personalized_agenda",
                        "description": "Criar agendas personalizadas por interesse",
                        "impact": "alto",
                        "implementation_ease": 5,
                        "target_metric": "satisfaction_score"
                    }
                ],
                "operational_optimizations": [
                    {
                        "action": "capacity_adjustment",
                        "description": "Ajustar capacidade baseado na demanda predita",
                        "impact": "mÃ©dio",
                        "implementation_ease": 9,
                        "target_metric": "occupancy_rate"
                    }
                ],
                "ai_generated_text": optimization_text,
                "timestamp": datetime.utcnow().isoformat(),
                "confidence_score": 0.8
            }
            
            logger.info(f"ğŸ”§ Generated automatic optimizations for event {event_id}")
            return optimizations
            
        except Exception as e:
            logger.error(f"âŒ Error generating automatic optimizations: {e}")
            return {"error": str(e)}

    async def _analyze_current_performance(self, metrics: Dict[str, float]) -> Dict[str, Any]:
        """Analisar performance atual do evento"""
        
        analysis = {
            "overall_score": 0.0,
            "strong_areas": [],
            "improvement_areas": [],
            "critical_issues": []
        }
        
        # Definir benchmarks
        benchmarks = {
            "attendance_rate": 0.8,
            "satisfaction_score": 4.0,
            "engagement_level": 0.7,
            "conversion_rate": 0.15,
            "revenue_per_participant": 100
        }
        
        scores = []
        for metric, value in metrics.items():
            if metric in benchmarks:
                benchmark = benchmarks[metric]
                score = min(value / benchmark, 1.2)  # Cap at 120% of benchmark
                scores.append(score)
                
                if score >= 1.1:
                    analysis["strong_areas"].append(f"{metric}: {value} (excelente)")
                elif score < 0.7:
                    analysis["improvement_areas"].append(f"{metric}: {value} (abaixo do esperado)")
                if score < 0.5:
                    analysis["critical_issues"].append(f"{metric}: {value} (crÃ­tico)")
        
        analysis["overall_score"] = np.mean(scores) if scores else 0.0
        
        return analysis

    async def _cache_models(self):
        """Cache dos modelos treinados"""
        try:
            if self.redis_client:
                # Cache perfis de usuÃ¡rio
                profiles_dict = {
                    user_id: asdict(profile) 
                    for user_id, profile in self.user_profiles.items()
                }
                await self.redis_client.setex(
                    "ai:user_profiles",
                    3600 * 24,  # 24 horas
                    json.dumps(profiles_dict)
                )
                
                # Cache embeddings de eventos
                embeddings_dict = {
                    event_id: embedding.tolist() 
                    for event_id, embedding in self.event_embeddings.items()
                }
                await self.redis_client.setex(
                    "ai:event_embeddings",
                    3600 * 24,  # 24 horas
                    json.dumps(embeddings_dict)
                )
                
        except Exception as e:
            logger.warning(f"âš ï¸ Could not cache models: {e}")

    def _fallback_content(
        self, 
        event_data: Dict[str, Any], 
        content_types: List[str]
    ) -> Dict[str, str]:
        """ConteÃºdo de fallback se IA falhar"""
        
        event_name = event_data.get('name', 'Evento Especial')
        
        fallback = {}
        for content_type in content_types:
            if content_type == "description":
                fallback[content_type] = f"Participe do {event_name}, um evento Ãºnico que vocÃª nÃ£o pode perder!"
            elif content_type == "marketing_copy":
                fallback[content_type] = f"ğŸ‰ {event_name} estÃ¡ chegando! Garante sua vaga agora!"
            elif content_type == "social_media":
                fallback[content_type] = f"ğŸ“… {event_name} - NÃ£o perca! #evento #imperdivel"
            elif content_type == "email_subject":
                fallback[content_type] = f"ğŸª {event_name} - Ãšltimas vagas!"
            elif content_type == "hashtags":
                fallback[content_type] = f"#{event_name.replace(' ', '')} #evento #networking"
            else:
                fallback[content_type] = f"ConteÃºdo sobre {event_name}"
        
        return fallback

    async def cleanup(self):
        """Limpeza de recursos"""
        try:
            if self.redis_client:
                await self.redis_client.close()
            logger.info("ğŸ§¹ AI Event Intelligence Engine cleanup completed")
        except Exception as e:
            logger.error(f"âŒ Error during cleanup: {e}")

# InstÃ¢ncia global do motor de IA
ai_intelligence_engine = AIEventIntelligenceEngine()